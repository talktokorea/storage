{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQmrOwNhLADT"
      },
      "source": [
        "# 9장. 웹 애플리케이션에 머신 러닝 모델 내장하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb-__7vELADW"
      },
      "source": [
        "**아래 링크를 통해 이 노트북을 주피터 노트북 뷰어(nbviewer.jupyter.org)로 보거나 구글 코랩(colab.research.google.com)에서 실행할 수 있습니다.**\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/rickiepark/python-machine-learning-book-2nd-edition/blob/master/code/ch09/ch09.ipynb\"><img src=\"https://jupyter.org/assets/main-logo.svg\" width=\"28\" />주피터 노트북 뷰어로 보기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/python-machine-learning-book-2nd-edition/blob/master/code/ch09/ch09.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Apu3p0GLADX"
      },
      "source": [
        "`watermark`는 주피터 노트북에 사용하는 파이썬 패키지를 출력하기 위한 유틸리티입니다. `watermark` 패키지를 설치하려면 다음 셀의 주석을 제거한 뒤 실행하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIA_CdDcLADX"
      },
      "outputs": [],
      "source": [
        "#!pip install watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjiHsG0yLADY",
        "outputId": "03792317-eb58-4364-eba2-8f1f6dff01df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "last updated: 2020-05-22 \n",
            "\n",
            "CPython 3.7.3\n",
            "IPython 7.5.0\n",
            "\n",
            "numpy 1.18.4\n",
            "pandas 1.0.3\n",
            "pyprind 2.11.2\n",
            "matplotlib 3.2.1\n",
            "nltk 3.4.1\n",
            "sklearn 0.23.1\n"
          ]
        }
      ],
      "source": [
        "%load_ext watermark\n",
        "%watermark -u -d -v -p numpy,pandas,pyprind,matplotlib,nltk,sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpwqFJR7LADZ"
      },
      "source": [
        "플래스크(Flask) 웹 애플리케이션 코드는 다음 디렉토리에 있습니다:\n",
        "    \n",
        "- `1st_flask_app_1/`: 간단한 플래스크 웹 애플리케이션\n",
        "- `1st_flask_app_2/`: `1st_flask_app_1`에 폼 검증과 렌더링을 추가하여 확장한 버전\n",
        "- `movieclassifier/`: 웹 애플리케이션에 내장한 영화 리뷰 분류기\n",
        "- `movieclassifier_with_update/`: `movieclassifier`와 같지만 초기화를 위해 sqlite 데이터베이스를 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1ZGlrNFLADZ"
      },
      "source": [
        "웹 애플리케이션을 로컬에서 실행하려면 `cd`로 (위에 나열된) 각 디렉토리에 들어가서 메인 애플리케이션 스크립트를 실행합니다.\n",
        "\n",
        "    cd ./1st_flask_app_1\n",
        "    python3 app.py\n",
        "    \n",
        "터미널에서 다음같은 내용일 출력됩니다.\n",
        "    \n",
        "     * Running on http://127.0.0.1:5000/\n",
        "     * Restarting with reloader\n",
        "     \n",
        "웹 브라우저를 열고 터미널에 출력된 주소(일반적으로 http://127.0.0.1:5000/)를 입력하여 웹 애플리케이션에 접속합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Obf9GOLADa"
      },
      "source": [
        "**이 튜토리얼로 만든 예제 애플리케이션 데모는 다음 주소에서 볼 수 있습니다: http://haesun.pythonanywhere.com/**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "33rIDvoCLADb"
      },
      "source": [
        "# 8장 정리 - 영화 리뷰 분류를 위한 모델 훈련하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRa0jf7cLADb"
      },
      "source": [
        "이 절은 8장의 마지막 섹션에서 훈련한 로지스틱 회귀 모델을 다시 사용합니다. 이어지는 코드 블럭을 실행하여 다음 절에서 사용할 모델을 훈련시키겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwElIw1WLADb"
      },
      "source": [
        "**노트**\n",
        "\n",
        "다음 코드는 8장에서 만든 `movie_data.csv` 데이터셋을 사용합니다.\n",
        "\n",
        "**코랩을 사용할 때는 다음 셀의 주석을 제거하고 실행하세요.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPcYhtI-LADc"
      },
      "outputs": [],
      "source": [
        "#!wget https://github.com/rickiepark/python-machine-learning-book-2nd-edition/raw/master/code/ch09/movie_data.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QQl_wwbLADc"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "\n",
        "\n",
        "with gzip.open('movie_data.csv.gz') as f_in, open('movie_data.csv', 'wb') as f_out:\n",
        "    f_out.writelines(f_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drI5npZuLADc",
        "outputId": "fcfd2393-486c-4da1-bd77-b851d2733754"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/haesun/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd-nxSxpLADd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = [w for w in text.split() if w not in stop]\n",
        "    return tokenized\n",
        "\n",
        "def stream_docs(path):\n",
        "    with open(path, 'r', encoding='utf-8') as csv:\n",
        "        next(csv) # skip header\n",
        "        for line in csv:\n",
        "            text, label = line[:-3], int(line[-2])\n",
        "            yield text, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY6JOoeNLADd",
        "outputId": "b6ddc510-dfd8-4bbc-b2c7-aea031870672"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\"',\n",
              " 1)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(stream_docs(path='movie_data.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuOa5jMcLADd"
      },
      "outputs": [],
      "source": [
        "def get_minibatch(doc_stream, size):\n",
        "    docs, y = [], []\n",
        "    try:\n",
        "        for _ in range(size):\n",
        "            text, label = next(doc_stream)\n",
        "            docs.append(text)\n",
        "            y.append(label)\n",
        "    except StopIteration:\n",
        "        return None, None\n",
        "    return docs, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLFaVjRALADe"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "vect = HashingVectorizer(decode_error='ignore', \n",
        "                         n_features=2**21,\n",
        "                         preprocessor=None, \n",
        "                         tokenizer=tokenizer)\n",
        "\n",
        "clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
        "doc_stream = stream_docs(path='movie_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLK4B6vvLADe"
      },
      "source": [
        "`pyprind`는 주피터 노트북에서 진행바를 출력하기 위한 유틸리티입니다. `pyprind` 패키지를 설치하려면 다음 셀의 주석을 제거한 뒤 실행하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCtqTK8wLADe"
      },
      "outputs": [],
      "source": [
        "#!pip install pyprind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsDpGLvALADf",
        "outputId": "c3a0cde2-46a8-45b5-c2cc-be889f9bbbb4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:21\n"
          ]
        }
      ],
      "source": [
        "import pyprind\n",
        "pbar = pyprind.ProgBar(45)\n",
        "\n",
        "classes = np.array([0, 1])\n",
        "for _ in range(45):\n",
        "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
        "    if not X_train:\n",
        "        break\n",
        "    X_train = vect.transform(X_train)\n",
        "    clf.partial_fit(X_train, y_train, classes=classes)\n",
        "    pbar.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nOzR5_vLADf",
        "outputId": "d37de93c-4b41-48fc-ea60-5219bbde2c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "정확도: 0.868\n"
          ]
        }
      ],
      "source": [
        "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
        "X_test = vect.transform(X_test)\n",
        "print('정확도: %.3f' % clf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaYiL8I0LADf"
      },
      "outputs": [],
      "source": [
        "clf = clf.partial_fit(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ry0WVyBgLADf"
      },
      "source": [
        "# 학습된 사이킷런 추정기 저장하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcMD4GSgLADf"
      },
      "source": [
        "앞에서 로지스틱 회귀 모델을 훈련한 후에 분류기, 불용어, 포터 어간 추출기, `HashingVectorizer`를 로컬 디스크에 직렬화된 객체로 저장합니다. 나중에 웹 애플리케이션에서 학습된 분류기를 이용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j283gFwqLADg"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "dest = os.path.join('movieclassifier', 'pkl_objects')\n",
        "if not os.path.exists(dest):\n",
        "    os.makedirs(dest)\n",
        "\n",
        "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol=4)   \n",
        "pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'), protocol=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0Yd0qTPLADg"
      },
      "source": [
        "그다음 나중에 임포트할 수 있도록 별도의 파일에 `HashingVectorizer`를 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCaY4ClxLADg",
        "outputId": "36d0a3e3-522a-42e2-b118-8528c9a91644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting movieclassifier/vectorizer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile movieclassifier/vectorizer.py\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "cur_dir = os.path.dirname(__file__)\n",
        "stop = pickle.load(open(\n",
        "                os.path.join(cur_dir, \n",
        "                'pkl_objects', \n",
        "                'stopwords.pkl'), 'rb'))\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
        "                           text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
        "                   + ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = [w for w in text.split() if w not in stop]\n",
        "    return tokenized\n",
        "\n",
        "vect = HashingVectorizer(decode_error='ignore',\n",
        "                         n_features=2**21,\n",
        "                         preprocessor=None,\n",
        "                         tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpfepqzJLADg"
      },
      "source": [
        "이전 코드 셀을 실행한 후에 객체가 올바르게 저장되었는지 확인하기 위해 IPython 노트북 커널을 재시작할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtNztTx6LADg"
      },
      "source": [
        "먼저 현재 파이썬 디렉토리를 `movieclassifer`로 변경합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "864IvbtkLADg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('movieclassifier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1gRMhvHLADg"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import re\n",
        "import os\n",
        "from vectorizer import vect\n",
        "\n",
        "clf = pickle.load(open(os.path.join('pkl_objects', 'classifier.pkl'), 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zg9CsAe6LADh",
        "outputId": "7566bd8f-8bda-41ec-b967-1aa2109938d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예측: 양성\n",
            "확률: 81.44%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "label = {0:'음성', 1:'양성'}\n",
        "\n",
        "example = ['I love this movie']\n",
        "X = vect.transform(example)\n",
        "print('예측: %s\\n확률: %.2f%%' %\\\n",
        "      (label[clf.predict(X)[0]], \n",
        "       np.max(clf.predict_proba(X))*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3nbV13DLADh"
      },
      "source": [
        "# 데이터 저장을 위해 SQLite 데이터베이스 설정하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr2rDSQyLADh"
      },
      "source": [
        "이 코드를 실행하기 전에 현재 위치가 `movieclassifier` 디렉토리인지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PwwRa_ILADh",
        "outputId": "dad4bac3-3a9c-4eeb-efd7-3b4eee840582"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/haesun/github/python-machine-learning-book-2nd-edition/code/ch09/movieclassifier'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErP_MRN7LADh"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('reviews.sqlite')\n",
        "c = conn.cursor()\n",
        "c.execute('DROP TABLE IF EXISTS review_db')\n",
        "c.execute('CREATE TABLE review_db (review TEXT, sentiment INTEGER, date TEXT)')\n",
        "\n",
        "example1 = 'I love this movie'\n",
        "c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (example1, 1))\n",
        "\n",
        "example2 = 'I disliked this movie'\n",
        "c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (example2, 0))\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeHD3TA8LADi"
      },
      "outputs": [],
      "source": [
        "conn = sqlite3.connect('reviews.sqlite')\n",
        "c = conn.cursor()\n",
        "\n",
        "c.execute(\"SELECT * FROM review_db WHERE date BETWEEN '2017-01-01 10:10:10' AND DATETIME('now')\")\n",
        "results = c.fetchall()\n",
        "\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZOcI-V6LADi",
        "outputId": "6b0e4361-50c3-479c-8a94-3336505c0ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('I love this movie', 1, '2020-05-22 11:06:59'), ('I disliked this movie', 0, '2020-05-22 11:06:59')]\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15TvLno0LADi"
      },
      "source": [
        "# 플라스크 웹 애플리케이션 개발하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8260bHhkLADi"
      },
      "source": [
        "## 영화 분류기 업데이트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx6x0blmLADi"
      },
      "source": [
        "다운로드한 깃허브 저장소에 들어있는 movieclassifier_with_update 디렉토리를 사용합니다(그렇지 않으면 `movieclassifier` 디렉토리를 복사해서 사용하세요)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa8l8LviLADi"
      },
      "source": [
        "**코랩을 사용할 때는 다음 셀의 주석을 제거하고 실행하세요.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD-h0epPLADi"
      },
      "outputs": [],
      "source": [
        "#!cp -r ../movieclassifier ../movieclassifier_with_update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AN3VeUbkLADj",
        "outputId": "0cd69c98-f4e0-4886-cc6e-1263ac21a42c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'./pkl_objects/classifier.pkl'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "os.chdir('../movieclassifier_with_update')\n",
        "shutil.copyfile('../movieclassifier/pkl_objects/classifier.pkl',\n",
        "                './pkl_objects/classifier.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smOtdPrsLADj"
      },
      "source": [
        "SQLite 데이터베이스에 저장된 데이터로 분류기를 업데이트하는 함수를 정의합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTQT8iHgLADj"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "\n",
        "# 로컬 디렉토리에서 HashingVectorizer를 임포트합니다\n",
        "from vectorizer import vect\n",
        "\n",
        "def update_model(db_path, model, batch_size=10000):\n",
        "\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    c = conn.cursor()\n",
        "    c.execute('SELECT * from review_db')\n",
        "    \n",
        "    results = c.fetchmany(batch_size)\n",
        "    while results:\n",
        "        data = np.array(results)\n",
        "        X = data[:, 0]\n",
        "        y = data[:, 1].astype(int)\n",
        "    \n",
        "        classes = np.array([0, 1])\n",
        "        X_train = vect.transform(X)\n",
        "        clf.partial_fit(X_train, y, classes=classes)\n",
        "        results = c.fetchmany(batch_size)\n",
        "    \n",
        "    conn.close()\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYbwErOzLADj"
      },
      "source": [
        "모델을 업데이트합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC1OPjp5LADj"
      },
      "outputs": [],
      "source": [
        "cur_dir = '.'\n",
        "\n",
        "# app.py 파일에 이 코드를 삽입했다면 다음 경로를 사용하세요.\n",
        "# import os\n",
        "# cur_dir = os.path.dirname(__file__)\n",
        "\n",
        "clf = pickle.load(open(os.path.join(cur_dir,\n",
        "                 'pkl_objects',\n",
        "                 'classifier.pkl'), 'rb'))\n",
        "db = os.path.join(cur_dir, 'reviews.sqlite')\n",
        "\n",
        "update_model(db_path=db, model=clf, batch_size=10000)\n",
        "\n",
        "# classifier.pkl 파일을 업데이트하려면 다음 주석을 해제하세요.\n",
        "\n",
        "# pickle.dump(clf, open(os.path.join(cur_dir, \n",
        "#             'pkl_objects', 'classifier.pkl'), 'wb')\n",
        "#             , protocol=4)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "ch09.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}